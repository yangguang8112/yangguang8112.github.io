<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      Archives: 2021 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="杨光">
    
    

    <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Archives: 2021">
<meta property="og:url" content="https://yangguang8112.github.io/archives/2021/index.html">
<meta property="og:site_name" content="二十一世纪是生命科学的">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Archives: 2021">
<meta name="twitter:description">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css">
    <!-- 临时修改方案，这行代码会是页面加载的时候强制把http转换成https，以解决博客是https要加载公式js库的时候浏览器阻止http的访问 -->
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">二十一世纪是生命科学的</a></h1>
        <hr class="panel-cover__divider" />

        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">

  
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/yangguang8112" title="Handsome boy on GitHub">
          <i class='icon icon-social-github'></i>
          <span class="label">GitHub</span>
        </a>
      </li>


    <!-- China social icon -->
    
    <!--
      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>
    -->
      <li class="navigation__item">
        <a href="http://weibo.com/1994YG?refer_flag=1001030101_&is_hot=1" title="一起下厕所">
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

  



  </ul>
</nav>

        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            


  <h1 class="archive-title">Archives: 2021</h1>
  <hr class="post-list__divider" />


<div class="main-post-list">
    <ol class="post-list">
    
    
    <li>

      <h2 class="post-list__post-title post-title">
        <a href="/2021/12/22/Automatic-cell-type-identification-methods-for-single-cell-RNA-sequencing/" title="link to Automatic cell type identification methods for single-cell RNA sequencing">Automatic cell type identification methods for single-cell RNA sequencing</a>
      </h2>

      <div class="post-list__meta">

        <time datetime="2021-12-22" class="post-list__meta--date date">2021-12-22</time> 
      </div>

      <div class="excerpt">
        
          <h3 id="任务描述"><a href="#任务描述" class="headerlink" title="任务描述"></a>任务描述</h3><p>Xie B et al(2021)描述了一个unlabel rate以及肿瘤相关的specificity和sensitivity，具体来说是评估一个模型能不能预测unlabel cell type以及，当用正常组织细胞训练，对预测肿瘤细胞做预测，将unlabel的预测结果看作是恶性细胞。</p>
        
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li>

      <h2 class="post-list__post-title post-title">
        <a href="/2021/09/23/bionlp数据集整理/" title="link to BioNLP数据集整理">BioNLP数据集整理</a>
      </h2>

      <div class="post-list__meta">

        <time datetime="2021-09-23" class="post-list__meta--date date">2021-09-23</time> 
      </div>

      <div class="excerpt">
        
          <p><img src="https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/167800228884052021678002288767.png" alt="20210830-151458.png"><br>图片来自于“Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing”</p>
        
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li>

      <h2 class="post-list__post-title post-title">
        <a href="/2021/08/27/A-Unified-MRC-Framework-for-Named-Entity-Recognition/" title="link to A Unified MRC Framework for Named Entity Recognition">A Unified MRC Framework for Named Entity Recognition</a>
      </h2>

      <div class="post-list__meta">

        <time datetime="2021-08-27" class="post-list__meta--date date">2021-08-27</time> 
      </div>

      <div class="excerpt">
        
          <p>把ner的序列标注问题做成是一个阅读理解的问题(MRC)。把训练数据变成(上下文，问题，答案)，训练的时候BERT的输入是把问题和上下文连起来用[SEP]分开，前后各加一个[CLS]。这就是为了和BERT保持一致。然后BERT的输出把第一句问题的表示向量给删了，只要后面上下文的表示向量。然后后面接了一个match model</p>
        
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li>

      <h2 class="post-list__post-title post-title">
        <a href="/2021/08/27/Joint-Biomedical-Entity-and-Relation-Extraction-with-Knowledge-Enhanced-Collective-Inference/" title="link to Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference">Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference</a>
      </h2>

      <div class="post-list__meta">

        <time datetime="2021-08-27" class="post-list__meta--date date">2021-08-27</time> 
      </div>

      <div class="excerpt">
        
          <p>提出一个新的利用外部知识的联合抽取框架KECI (Knowledge-Enhanced Collective Inference)</p>
<h2 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h2><p>分三步：</p>
<ol>
<li>将input text结构化为初始化图(initial span graph)，作为对输入文本的初步理解。在一个span graph里每个node表示一个entity，每条edge表示两个entity的relation</li>
<li>然后在一个额外的知识库里使用entities linker形成一个包含所有潜在有关联的生物医学实体的背景知识图(background knowledge graph)，对于每个entity从上面提到的知识库(KB)里提取它的semantic types，definition sentence以及relational information</li>
<li>最后KECI使用注意力机制融合上述两个graph成一个更refined的graph</li>
</ol>
        
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li>

      <h2 class="post-list__post-title post-title">
        <a href="/2021/08/11/A-Unified-Generative-Framework-for-Various-NER-Subtasks/" title="link to A Unified Generative Framework for Various NER Subtasks">A Unified Generative Framework for Various NER Subtasks</a>
      </h2>

      <div class="post-list__meta">

        <time datetime="2021-08-11" class="post-list__meta--date date">2021-08-11</time> 
      </div>

      <div class="excerpt">
        
          <p>核心思想：不做序列标注了，把ner任务转换成文本生成任务，用一个seq2seq模型去生成一个entity span sequence，这样就不需要设计复制的tagging模式了</p>
<p>seq2seq模型是用的BART</p>
<h5 id="原文"><a href="#原文" class="headerlink" title="原文"></a>原文</h5><p><a href="https://aclanthology.org/2021.acl-long.451">A Unified Generative Framework for Various NER Subtasks</a></p>
        
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li>

      <h2 class="post-list__post-title post-title">
        <a href="/2021/06/15/Knowledge-Enhanced-Contextual-Word-Representations/" title="link to Knowledge Enhanced Contextual Word Representations">Knowledge Enhanced Contextual Word Representations</a>
      </h2>

      <div class="post-list__meta">

        <time datetime="2021-06-15" class="post-list__meta--date date">2021-06-15</time> 
      </div>

      <div class="excerpt">
        
          <h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><h3 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h3><p>用的实体链接，在原生预训练模型的两层之间加入实体链接层，把实体在KG中相关的entity embedding加到下一层的预训练模型<br><img src="\img\20210615-110419.png"></p>
        
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li>

      <h2 class="post-list__post-title post-title">
        <a href="/2021/05/20/KEPLER/" title="link to KEPLER">KEPLER</a>
      </h2>

      <div class="post-list__meta">

        <time datetime="2021-05-20" class="post-list__meta--date date">2021-05-20</time> 
      </div>

      <div class="excerpt">
        
          <blockquote>
<p>KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation</p>
</blockquote>
<p>这篇论文提出一种模型能统一知识embedding和预训练语言表示（Knowledge Embeddingand Pre-trained LanguagE Representation (KEPLER)）<br>
        
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li>

      <h2 class="post-list__post-title post-title">
        <a href="/2021/04/22/K-ADAPTER/" title="link to K-ADAPTER">K-ADAPTER</a>
      </h2>

      <div class="post-list__meta">

        <time datetime="2021-04-22" class="post-list__meta--date date">2021-04-22</time> 
      </div>

      <div class="excerpt">
        
          <p>大多数之前的工作通过多任务学习来注入知识和更新模型参数以增强预训练语言模型。不管他们用了哪些方法做知识注入，遇到的共同问题就是对前面知识的灾难性遗忘。figure1a<br>figure1b是我们提出的K-ADAPTER，不同类型的知识被注入到不同的袖珍神经网络模型（比如本文中的adapter），他们之间互相独立，而不是直接注入到预训练模型。这样既能固定预训练模型的原始表示，又支持继续知识注入。adapter是一个含有特定知识的模型，是独立于预训练模型之外的插件。<br>
        
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li>

      <h2 class="post-list__post-title post-title">
        <a href="/2021/03/10/CoLAKE/" title="link to CoLAKE">CoLAKE</a>
      </h2>

      <div class="post-list__meta">

        <time datetime="2021-03-10" class="post-list__meta--date date">2021-03-10</time> 
      </div>

      <div class="excerpt">
        
          <p>提出了一个方法可以同时做语言和知识的表征，并且在需要知识的任务中有较好的表现，在一些NLU（不太需要知识）的任务也没有降很多。<br>把输入的句子看成是一个全连接的graph，即word graph。然后根据句子中的实体到知识图谱中找一级三元组，只找对应实体的第一层邻居。然后将句子中的实体作为锚点（ancher node），以锚节点为中心抽出sub-knowledge-graph，然后根据锚点将sub-knowledge-graph和word graph合并。这是示意图是这样的，实际操作起来，在输入的时候这些node也是序列摆放，他们的graph结构是通过position embedding和mask矩阵来体现的。<br>
        
      </div>

      <hr class="post-list__divider" />
    </li>
    
    <li>

      <h2 class="post-list__post-title post-title">
        <a href="/2021/01/30/RoBERTa/" title="link to RoBERTa">RoBERTa</a>
      </h2>

      <div class="post-list__meta">

        <time datetime="2021-01-30" class="post-list__meta--date date">2021-01-30</time> 
      </div>

      <div class="excerpt">
        
          <p>主要是训练方法上的创新，该paper认为bert的训练明显不够，他们对超参调优和训练集大小的影响的仔细评估。提出RoBERTa这个recipe来提高BERT的训练效果。<br>
        
      </div>

      <hr class="post-list__divider" />
    </li>
    
  </ol>

  <hr class="post-list__divider " />

<nav class="pagination" role="navigation">
    

    <span class="pagination__page-number"> 1 / 1</span>
    
    
</nav>


</div>
            <footer class="footer">

    <span class="footer__copyright">SynapseLab &copy; 2016-2024.</span>
    
</footer>
        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    

    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?5ed7e5c6530f805ef5b2f6d9c187ded6";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
